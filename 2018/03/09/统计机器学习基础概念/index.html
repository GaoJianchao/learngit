<!DOCTYPE html><html lang="zh-CN"><head><meta http-equiv="content-type" content="text/html; charset=utf-8"><meta content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=0" name="viewport"><meta content="yes" name="apple-mobile-web-app-capable"><meta content="black-translucent" name="apple-mobile-web-app-status-bar-style"><meta content="telephone=no" name="format-detection"><meta name="description"><title>统计机器学习基本概念 | 潇洒一世</title><link rel="stylesheet" type="text/css" href="/learngit/css/style.css?v=0.0.0"><link rel="stylesheet" type="text/css" href="//cdn.bootcss.com/normalize/7.0.0/normalize.min.css"><link rel="stylesheet" type="text/css" href="//cdn.bootcss.com/pure/1.0.0/pure-min.css"><link rel="stylesheet" type="text/css" href="//cdn.bootcss.com/pure/1.0.0/grids-responsive-min.css"><link rel="stylesheet" href="//cdn.bootcss.com/font-awesome/4.7.0/css/font-awesome.min.css"><script type="text/javascript" src="//cdn.bootcss.com/jquery/3.2.1/jquery.min.js"></script><link rel="Shortcut Icon" type="image/x-icon" href="/learngit/favicon.ico"><link rel="apple-touch-icon" href="/learngit/apple-touch-icon.png"><link rel="apple-touch-icon-precomposed" href="/learngit/apple-touch-icon.png"></head><body><div class="body_container"><div id="header"><div class="site-name"><h1 class="hidden">统计机器学习基本概念</h1><a id="logo" href="/learngit/.">潇洒一世</a><p class="description">高建超的博客</p></div><div id="nav-menu"><a class="current" href="/learngit/."><i class="fa fa-home"> 首页</i></a><a href="/learngit/archives/"><i class="fa fa-archive"> 归档</i></a><a href="/learngit/about/"><i class="fa fa-user"> 关于</i></a><a href="/learngit/history/"><i class="fa fa-book"> 历史</i></a><a href="/learngit/atom.xml"><i class="fa fa-rss"> 订阅</i></a></div></div><div class="pure-g" id="layout"><div class="pure-u-1 pure-u-md-3-4"><div class="content_container"><div class="post"><h1 class="post-title">统计机器学习基本概念</h1><div class="post-meta">Mar 9, 2018<span> | </span><span class="category"><a href="/learngit/categories/技术基础/">技术基础</a></span><script src="https://dn-lbstatics.qbox.me/busuanzi/2.3/busuanzi.pure.mini.js" async></script><span id="busuanzi_container_page_pv"> | <span id="busuanzi_value_page_pv"></span><span> 阅读</span></span></div><div class="post-content"><blockquote>
<ul>
<li>统计学习是关于计算机基于数据构建概率统计模型并应用模型对数据进行分析与预测的一门学科;</li>
<li>监督学习：从给定有限的训练数据出发，假设数据是独立同分布的，而且假设模型属于某个假设空间，应用某一评价准则，从假设空间中选取一个最优的模型，使它对已给训练数据及未知测试数据在给定评价标准意义下有最准确的预测。</li>
</ul>
</blockquote>
<p>统计机器学习分为监督学习，无监督学习，半监督学习，增强学习。</p>
<h2 id="监督学习"><a href="#监督学习" class="headerlink" title="监督学习"></a>监督学习</h2><p>输入空间、特征空间、输出空间、联合概率率分布（基本假设）、假设空间。<br><strong>特征空间</strong>：每个样本实例由特征向量表示，所有特征向量组成的空间就是特征空间。特征空间的每一维对应于一个特征，有时特征空间和输入空间一致，但有时不一致，故需将输入空间映射到特征空间。<strong>模型实际上是定义在特征空间上的。</strong><br><strong>假设空间</strong>：输入空间到输出空间的映射集合。</p>
<h2 id="统计机器学习三要素"><a href="#统计机器学习三要素" class="headerlink" title="统计机器学习三要素"></a>统计机器学习三要素</h2><p><strong>模型</strong>：所要学习的条件概率分布或者决策函数。模型的假设空间就是所有可能的集合。<br><strong>策略</strong>：有了假设空间，要考虑按照什么样的准则选择最优的模型，这准则就是策略。<br><strong>算法</strong>：是指对选择出的最优模型用计算方法求解。这就将问题转化为最优化问题，但一般没有显式的解析解，这就需要数值计算方法求解。</p>
<h3 id="策略"><a href="#策略" class="headerlink" title="策略"></a>策略</h3><p>损失函数用来度量预测错误的程度，一般有四种函数：</p>
<ol>
<li>0-1损失函数：<br>$$ L(Y,f(X))=\begin{cases}<br>1, Y \neq f(X)\\<br>0, Y=f(X)<br>\end{cases}<br>$$</li>
<li>平方损失函数:<br>$$ L(Y, f(X))=(Y-f(X))^2 $$</li>
<li>绝对损失函数:<br>$$ L(Y, f(X))=|Y-f(X)| $$</li>
<li>对数损失函数:<br>$$ L(Y, f(X))=-logP(Y|X) $$</li>
</ol>
<p><strong>期望损失</strong>：模型关于联合分布的平均损失。学习的目标是选择期望风险最小的模型。但是联合概率分布一般是未知的，就不能求出条件概率分布。但<strong>经验风险：模型关于训练样本集的平均损失</strong>，根据大数定律，当样本容量趋于无穷大时，经验风险趋于期望风险。但是现实样本数是有限的，所以要对经验风险进行改进，这就关联了监督学习的两个基本策略：<strong>经验风险最小化和结构风险最小化</strong>。</p>
<p>经验风险最小的模型认为是最优的模型，这是当样本容量很大时来说的。当样本容量很小时，学习的效果未必好，所以可能出现“过拟合”现象。为了避免过拟合，就有了结构化风险最小化模型（等价于正则化）：其实就是在经验风险最小化的基础上加上正则项（模型复杂度）。这时需要两者都最小才是最优模型。举例：结构风险最小化：极大似然估计（模型是条件概率分布，损失函数是对数函数），结构风险最小化：最大后验概率估计（模型是条件概率分布，损失函数是对数函数，正则化是模型的先验概率）。</p>
<h2 id="模型评估和选择"><a href="#模型评估和选择" class="headerlink" title="模型评估和选择"></a>模型评估和选择</h2><h3 id="评估"><a href="#评估" class="headerlink" title="评估"></a>评估</h3><p><strong>训练误差</strong>：随模型复杂度的增加而减小。<br><strong>测试误差</strong>：随模型复杂度的增加先减小后增大。<br><strong>过拟合</strong>：模型的参数过多，以致于出现对训练集预测的好，对测试集预测的差的现象。<strong>模型选择就是要避免过拟合并提高模型的预测能力。</strong></p>
<h3 id="选择"><a href="#选择" class="headerlink" title="选择"></a>选择</h3><p>两种方法：正则化、交叉验证<br>正则化项：一般是模型复杂度的单调递增函数，可以是模型参数向量的范数（L1、L2等）。<br>交叉验证：将数据进行切分为训练集和测试集，反复训练、测试以及模型选择。（分类问题中样本足够多时，可能分为训练集（用于训练模型）、验证集（模型的选择）、测试集（对学习方法的评估））</p>
<h2 id="泛化能力"><a href="#泛化能力" class="headerlink" title="泛化能力"></a>泛化能力</h2><p>泛化误差（期望风险）：模型对未知数据的预测能力。<br>泛化误差上界：它是样本容量的单调递减函数，当样本容量增加时，泛化误差趋于0；它还是假设空间的log函数，空间越大，泛化误差越大。</p>
<h2 id="生成模型和判别模型"><a href="#生成模型和判别模型" class="headerlink" title="生成模型和判别模型"></a>生成模型和判别模型</h2><p><strong>生成方法特点</strong>：可以还原出联合概率分布P（X,Y），而判别不行；学习收敛速度快，随样本容量的增加可以更快收敛于真实模型；当存在隐变量时，也适用，但判别不行。<br><strong>判别方法特点</strong>：直接学习条件概率模型或者决策函数；学习准确率高，可以对数据进行各种程度上的抽象、定义特征和使用特征，简化学习问题。</p>
<p>##分类问题<br>评价指标：准确率、精确率、召回率、F1.<br>精确率：正类正确分类的数量占所有分为正类的比例；<br>召回率：正类正确分类的数量占所有正确分类的比例；<br>F1：精确率和召回率的调和均值。<br><strong>标注问题</strong>：输入输出都是序列。<br><strong>回归问题</strong>：选择一条曲线更好地拟合一直数据且更好地预测位置数据。</p>
</div><div class="tags"><a href="/learngit/tags/机器学习/">机器学习</a><a href="/learngit/tags/统计学习/">统计学习</a></div><div class="post-nav"><a class="pre" href="/learngit/2018/03/10/决策树/">决策树</a><a class="next" href="/learngit/2018/03/05/hello-world/">Hello World</a></div><div id="lv-container" data-id="city" data-uid="MTAyMC8zNDcxMS8xMTI0OA"><script>(function(d, s) {
   var j, e = d.getElementsByTagName(s)[0];
   if (typeof LivereTower === 'function') { return; }
   j = d.createElement(s);
   j.src = 'https://cdn-city.livere.com/js/embed.dist.js';
   j.async = true;
   e.parentNode.insertBefore(j, e);
})(document, 'script');
</script></div></div></div></div><div class="pure-u-1 pure-u-md-1-4"><div id="sidebar"><div class="widget"><form class="search-form" action="//www.baidu.com/baidu" method="get" accept-charset="utf-8" target="_blank"><input type="search" name="word" maxlength="20" placeholder="Search"/><input type="hidden" name="si" value="https://GaoJianchao.github.io/learngit"/><input name="tn" type="hidden" value="bds"/><input name="cl" type="hidden" value="3"/><input name="ct" type="hidden" value="2097152"/><input name="s" type="hidden" value="on"/></form></div><div class="widget"><div class="widget-title"><i class="fa fa-folder-o"> 分类</i></div><ul class="category-list"><li class="category-list-item"><a class="category-list-link" href="/learngit/categories/技术基础/">技术基础</a></li><li class="category-list-item"><a class="category-list-link" href="/learngit/categories/算法/">算法</a></li></ul></div><div class="widget"><div class="widget-title"><i class="fa fa-star-o"> 标签</i></div><div class="tagcloud"><a href="/learngit/tags/机器学习/" style="font-size: 15px;">机器学习</a> <a href="/learngit/tags/Python/" style="font-size: 15px;">Python</a> <a href="/learngit/tags/MATLAB/" style="font-size: 15px;">MATLAB</a> <a href="/learngit/tags/kNN/" style="font-size: 15px;">kNN</a> <a href="/learngit/tags/决策树算法/" style="font-size: 15px;">决策树算法</a> <a href="/learngit/tags/朴素贝叶斯/" style="font-size: 15px;">朴素贝叶斯</a> <a href="/learngit/tags/统计学习/" style="font-size: 15px;">统计学习</a> <a href="/learngit/tags/逻辑回归/" style="font-size: 15px;">逻辑回归</a> <a href="/learngit/tags/支持向量机/" style="font-size: 15px;">支持向量机</a> <a href="/learngit/tags/隐马尔可夫模型/" style="font-size: 15px;">隐马尔可夫模型</a></div></div><div class="widget"><div class="widget-title"><i class="fa fa-file-o"> 最近文章</i></div><ul class="post-list"><li class="post-list-item"><a class="post-list-link" href="/learngit/2018/03/15/隐马尔可夫模型/">隐马尔可夫模型</a></li><li class="post-list-item"><a class="post-list-link" href="/learngit/2018/03/14/朴素贝叶斯/">朴素贝叶斯</a></li><li class="post-list-item"><a class="post-list-link" href="/learngit/2018/03/13/kNN算法/">kNN算法</a></li><li class="post-list-item"><a class="post-list-link" href="/learngit/2018/03/12/逻辑回归与支持向量机/">逻辑回归与支持向量机</a></li><li class="post-list-item"><a class="post-list-link" href="/learngit/2018/03/10/决策树/">决策树</a></li><li class="post-list-item"><a class="post-list-link" href="/learngit/2018/03/09/统计机器学习基础概念/">统计机器学习基本概念</a></li><li class="post-list-item"><a class="post-list-link" href="/learngit/2018/03/05/hello-world/">Hello World</a></li></ul></div><div class="widget"><div class="widget-title"><i class="fa fa-external-link"> 友情链接</i></div><ul></ul><a href="https://github.com/GaoJianchao" title="github" target="_blank">github</a><ul></ul><a href="http://di1shuai.com" title="朱帅的博客" target="_blank">朱帅的博客</a><ul></ul><a href="https://github.com/BestBurning/maupassant-hexo" title="Maupassant" target="_blank">Maupassant</a></div></div></div><div class="pure-u-1 pure-u-md-3-4"><div id="footer">Copyright © 2018 <a href="/learngit/." rel="nofollow">潇洒一世|</a> Powered by<a rel="nofollow" target="_blank" href="https://hexo.io"> Hexo.</a> My<a rel="nofollow" target="_blank" href="https://github.com/GaoJianchao"> Github.</a></div></div></div><a class="show" id="rocket" href="#top"></a><script type="text/javascript" src="/learngit/js/totop.js?v=0.0.0" async></script><script type="text/javascript" src="//cdn.bootcss.com/fancybox/3.2.5/jquery.fancybox.min.js" async></script><script type="text/javascript" src="/learngit/js/fancybox.js?v=0.0.0" async></script><link rel="stylesheet" type="text/css" href="//cdn.bootcss.com/fancybox/3.2.5/jquery.fancybox.min.css"><script type="text/x-mathjax-config">MathJax.Hub.Config({
  tex2jax: {inlineMath: [['$','$'], ['\\(','\\)']]}
  });
</script><script type="text/javascript" src="//cdn.bootcss.com/mathjax/2.7.2/MathJax.js?config=TeX-MML-AM_CHTML" async></script><script type="text/javascript" src="/learngit/js/codeblock-resizer.js?v=0.0.0"></script><script type="text/javascript" src="/learngit/js/smartresize.js?v=0.0.0"></script></div></body></html>