<!DOCTYPE html><html lang="zh-CN"><head><meta http-equiv="content-type" content="text/html; charset=utf-8"><meta content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=0" name="viewport"><meta content="yes" name="apple-mobile-web-app-capable"><meta content="black-translucent" name="apple-mobile-web-app-status-bar-style"><meta content="telephone=no" name="format-detection"><meta name="description"><title>逻辑回归与支持向量机 | 潇洒一世</title><link rel="stylesheet" type="text/css" href="/learngit/css/style.css?v=0.0.0"><link rel="stylesheet" type="text/css" href="//cdn.bootcss.com/normalize/7.0.0/normalize.min.css"><link rel="stylesheet" type="text/css" href="//cdn.bootcss.com/pure/1.0.0/pure-min.css"><link rel="stylesheet" type="text/css" href="//cdn.bootcss.com/pure/1.0.0/grids-responsive-min.css"><link rel="stylesheet" href="//cdn.bootcss.com/font-awesome/4.7.0/css/font-awesome.min.css"><script type="text/javascript" src="//cdn.bootcss.com/jquery/3.2.1/jquery.min.js"></script><link rel="Shortcut Icon" type="image/x-icon" href="/learngit/favicon.ico"><link rel="apple-touch-icon" href="/learngit/apple-touch-icon.png"><link rel="apple-touch-icon-precomposed" href="/learngit/apple-touch-icon.png"></head><body><div class="body_container"><div id="header"><div class="site-name"><h1 class="hidden">逻辑回归与支持向量机</h1><a id="logo" href="/learngit/.">潇洒一世</a><p class="description">高建超的博客</p></div><div id="nav-menu"><a class="current" href="/learngit/."><i class="fa fa-home"> 首页</i></a><a href="/learngit/archives/"><i class="fa fa-archive"> 归档</i></a><a href="/learngit/about/"><i class="fa fa-user"> 关于</i></a><a href="/learngit/history/"><i class="fa fa-book"> 历史</i></a><a href="/learngit/atom.xml"><i class="fa fa-rss"> 订阅</i></a></div></div><div class="pure-g" id="layout"><div class="pure-u-1 pure-u-md-3-4"><div class="content_container"><div class="post"><h1 class="post-title">逻辑回归与支持向量机</h1><div class="post-meta">Mar 12, 2018<span> | </span><span class="category"><a href="/learngit/categories/技术基础/">技术基础</a></span><script src="https://dn-lbstatics.qbox.me/busuanzi/2.3/busuanzi.pure.mini.js" async></script><span id="busuanzi_container_page_pv"> | <span id="busuanzi_value_page_pv"></span><span> 阅读</span></span></div><div class="post-content"><p>逻辑回归可以用于二类或多类分类，它是源自逻辑斯谛分布。支持向量机是一种二类分类模型。</p>
<h2 id="逻辑回归"><a href="#逻辑回归" class="headerlink" title="逻辑回归"></a>逻辑回归</h2><p>首先，逻辑回归模型的分布函数是S型曲线（sigmoid函数）：<br>$$h_w(x)=g(w^Tx)=\frac{1}{1+e^{-w^Tx}}$$即：<br>$$g(z)=\frac{1}{1+e^{-z}}$$<br> ![S函数曲线][1]</p>
<h3 id="逻辑回归模型"><a href="#逻辑回归模型" class="headerlink" title="逻辑回归模型"></a>逻辑回归模型</h3><p>假定条件概率分布：<br>$$P(Y=1|x)=h_w(x)</p>
<p>P(Y=0|x)=1-h_w(x)$$<br><strong>模型参数估计</strong>：<br>使用极大似然估计法估计模型参数，则似然函数为：<br>$$\prod_{i=1}^N[h_w(x_i)]^{y_i}[1-h_w(x_i)]^{1-y_i}$$<br>对数似然函数为<br>$$<br>L(w)=\sum_{i=1}^N[{y_i}logh_w(x_i)+(1-y_i)log(1-h_w(x_i))] \<br>=\sum_{i=1}^N[y_ilog\frac{h_w(x_i)}{(1-h_w(x_i))}+log((1-h_w(x_i)))] \<br>=\sum_{i=1}^N[y_i(w^Tx_i)-log(1+e^{w^Tx_i})]<br>$$<br>对L（w）求极大值，得到w的估计值：<br>$$<br>\frac{\partial L(w)}{\partial w_i}=\sum_{i=1}^N (y_ix_i-h_w(x_i)x_i)<br>$$<br>学习中通常采用梯度下降法以及拟牛顿法。<br>则最后求得逻辑回归模型：<br>$$<br>y_i=\begin{cases}<br>h_w(x_i), y_i=1\<br>1-h_w(x_i), y_i=0<br>\end{cases}<br>$$<br><strong>多分类逻辑回归</strong><br>对于<strong>多分类</strong>来说，将逻辑回归模型推广到多项逻辑回归模型<br>$$P(Y=k|x)=\frac{e^{w_k^Tx}}{1+\sum_{k=1}^{K-1} e^{w_k^Tx}}, k=1,2,…,K-1 \<br>P(Y=K|x)=\frac{1}{1+\sum_{k=1}^{K-1}e^{w_k^Tx}}<br>$$</p>
<h2 id="支持向量机"><a href="#支持向量机" class="headerlink" title="支持向量机"></a>支持向量机</h2><p>支持向量机基础是定义在特征空间上的间隔最大的线性分类器，间隔最大使它有别于感知机。此外，它还包括核方法，这使得它成为非线性分类器。它的学习算法是求解凸二次规划的最优化算法。</p>
<ul>
<li><strong>线性可分支持向量机</strong>：训练数据集是线性可分的，通过硬间隔最大化，学习线性分类器；</li>
<li><strong>线性支持向量机</strong>：训练数据集是线性近似可分的，通过软间隔最大化，学习线性分类器；</li>
<li><strong>非线性支持向量机</strong>：训练数据集是非线性可分的，通过核技巧和软间隔最大化，学习非线性分类器。</li>
</ul>
<p><strong>输入都由输入空间转换到特征空间，支持向量机的学习是在特征空间进行的。</strong></p>
<blockquote>
<p>注：当训练数据集线性可分时，存在无穷个分离超平面可将两类数据正确分开。感知机利用误分类最小的策略，求得分离超平面，不过这时的解有无穷多个。线性可分支持向量机利用间隔最大化求最优分离超平面，解是唯一的。</p>
</blockquote>
<h3 id="线性可分支持向量机"><a href="#线性可分支持向量机" class="headerlink" title="线性可分支持向量机"></a>线性可分支持向量机</h3><p><strong>函数间隔</strong><br>一个点距离分离超平面的远近表示分类的确信度。$w^Tx+b$的符号与类y的符号是否一致表示分类的正确性，所以函数间隔来表示两者,超平面对一个样本点来说的函数间隔：<br>$$\hat\gamma_i=y_i(w^Tx_i+b)$$<br>只有函数间隔选择分离超平面不够，因为当$w,b$成倍增加时，函数间隔也成倍增加，超平面虽然没有变，但是点到面距离大了，所以要引入<strong>几何间隔</strong>（对$w$加上某些约束）。</p>
<p><strong>几何间隔</strong><br>也就是函数间隔除以$||w||$,即：<br>$$\gamma_i=y_i(\frac{w}{||w||}\cdot x_i+\frac{b}{||w||})$$<br>所以当$||w||=1$时，函数间隔等于几何间隔，当$w,b$成倍增加时（超平面没改变），函数间隔改变了，但几何间隔没改变。</p>
<p><strong>间隔最大化</strong><br>约束最优化问题：<br>$$\max_{w,b} \frac{\hat\gamma}{||w||} \<br>s.t. y_i(w \cdot x_i+b)\geq \hat\gamma, i=1,2,…,N<br>$$<br>表示样本点的几何间隔至少为$\hat\gamma/||w||$。han’shu函数间隔的取值并不影响最优化问题的解，函数间隔的改变对上面的最优化问题不等式约束没有影响，对目标函数优化也没有影响，所以取$\hat\gamma=1$，等价的最小化问题(凸二次规划问题)：<br>$$\min_{w,b} \frac{1}{2}||w||^2\<br>s.t. y_i(w \cdot x_i+b)-1 \geq 0, i=1,2,…,N<br>$$</p>
<p><strong>支持向量和间隔边界</strong><br>支持向量在超平面上，也就是间隔边界上，两个间隔边界的距离等于$2/||w||$,在决定分离超平面时只有支持向量起作用，而其他实例点不起作用。由于支持向量（重要的训练样本点）在确定分离超平面时起决定性作用，所以称为支持向量机。</p>
<p><strong>学习算法</strong><br>为了求解原问题的凸二次规划问题，需要借助拉格朗日对偶性转化为对偶问题进行求解。<br><strong>对偶问题优点：</strong></p>
<ul>
<li>更容易求解；</li>
<li>自然引入核函数，推广到非线性分类问题。</li>
</ul>
<p>1、构建拉格朗日函数：<br>$$<br>L(w,b,\alpha)=\frac{1}{2}||w||^2-\sum_{i=1}^N \alpha_iy_i(w \cdot x_i+b)+\sum_{i=1}^N \alpha_i<br>$$<br>2、转化为对偶问题,先对$w,b$求极小，再对$\alpha$求极大：<br>$$\max_\alpha \min_{w,b}L(w,b,\alpha)$$<br>对$w,b$求极小：<br>$$\nabla_wL(w,b,\alpha)=w-\sum_{i=1}^N \alpha_iy_ix_i=0 \<br>\nabla_bL(w,b,\alpha)=\sum_{i=1}^N\alpha_iy_i=0 \<br>w=\sum_{i=1}^N\alpha_iy_ix_i \<br>\sum_{i=1}^N\alpha_iy_i=0<br>$$<br>代入$L(w,b,\alpha)$：<br>$$L(w,b,\alpha)=\frac{1}{2}w^Tw-w^T\sum_{i=1}^N \alpha_iy_ix_i-\sum_{i=1}^N \alpha_iy_ib+\sum_{i=1}^N\alpha_i \<br>=\frac{1}{2}w^T\sum_{i=1}^N \alpha_iy_ix_i-w^T\sum_{i=1}^N \alpha_iy_ix_i-\sum_{i=1}^N \alpha_iy_ib+\sum_{i=1}^N\alpha_i \<br>=-\frac{1}{2}w^T\sum_{i=1}^N \alpha_iy_ix_i-\sum_{i=1}^N \alpha_iy_ib+\sum_{i=1}^N\alpha_i \<br>=-\frac{1}{2}\sum_{i=1}^N\alpha_iy_ix_i^T\sum_{i=1}^N \alpha_iy_ix_i+\sum_{i=1}^N\alpha_i \<br>=-\frac{1}{2}\sum_{i=1}^N\sum_{j=1}^N \alpha_i\alpha_jy_iy_jx_i^T x_j+\sum_{i=1}^N\alpha_i<br>$$<br>3、对$\alpha$求极大，相当于对以下求极小：<br>$$\min_\alpha \frac{1}{2}\sum_{i=1}^N\sum_{j=1}^N \alpha_i\alpha_jy_iy_jx_i^T x_j-\sum_{i=1}^N\alpha_i \<br>s.t. \sum_{i=1}^N\alpha_iy_i=0 \<br>\alpha_i \geq 0, i=1,2,…,N<br>$$<br>通过SMO算法求解$\alpha$，之后求出$w,b$，最后求出分离超平面和分类决策函数。<br>[1]: <a href="https://raw.githubusercontent.com/GaoJianchao/learngit/master/img/S.png" target="_blank" rel="noopener">https://raw.githubusercontent.com/GaoJianchao/learngit/master/img/S.png</a></p>
</div><div class="tags"><a href="/learngit/tags/机器学习，逻辑回归/">机器学习，逻辑回归</a><a href="/learngit/tags/支持向量机/">支持向量机</a></div><div class="post-nav"><a class="next" href="/learngit/2018/03/10/决策树/">决策树</a></div><div id="lv-container" data-id="city" data-uid="MTAyMC8zNDcxMS8xMTI0OA"><script>(function(d, s) {
   var j, e = d.getElementsByTagName(s)[0];
   if (typeof LivereTower === 'function') { return; }
   j = d.createElement(s);
   j.src = 'https://cdn-city.livere.com/js/embed.dist.js';
   j.async = true;
   e.parentNode.insertBefore(j, e);
})(document, 'script');
</script></div></div></div></div><div class="pure-u-1 pure-u-md-1-4"><div id="sidebar"><div class="widget"><form class="search-form" action="//www.baidu.com/baidu" method="get" accept-charset="utf-8" target="_blank"><input type="search" name="word" maxlength="20" placeholder="Search"/><input type="hidden" name="si" value="https://GaoJianchao.github.io/learngit"/><input name="tn" type="hidden" value="bds"/><input name="cl" type="hidden" value="3"/><input name="ct" type="hidden" value="2097152"/><input name="s" type="hidden" value="on"/></form></div><div class="widget"><div class="widget-title"><i class="fa fa-folder-o"> 分类</i></div><ul class="category-list"><li class="category-list-item"><a class="category-list-link" href="/learngit/categories/技术基础/">技术基础</a></li><li class="category-list-item"><a class="category-list-link" href="/learngit/categories/算法/">算法</a></li></ul></div><div class="widget"><div class="widget-title"><i class="fa fa-star-o"> 标签</i></div><div class="tagcloud"><a href="/learngit/tags/机器学习/" style="font-size: 15px;">机器学习</a> <a href="/learngit/tags/Python/" style="font-size: 15px;">Python</a> <a href="/learngit/tags/MATLAB/" style="font-size: 15px;">MATLAB</a> <a href="/learngit/tags/统计学习/" style="font-size: 15px;">统计学习</a> <a href="/learngit/tags/机器学习，决策树算法/" style="font-size: 15px;">机器学习，决策树算法</a> <a href="/learngit/tags/机器学习，逻辑回归/" style="font-size: 15px;">机器学习，逻辑回归</a> <a href="/learngit/tags/支持向量机/" style="font-size: 15px;">支持向量机</a></div></div><div class="widget"><div class="widget-title"><i class="fa fa-file-o"> 最近文章</i></div><ul class="post-list"><li class="post-list-item"><a class="post-list-link" href="/learngit/2018/03/12/逻辑回归与支持向量机/">逻辑回归与支持向量机</a></li><li class="post-list-item"><a class="post-list-link" href="/learngit/2018/03/10/决策树/">决策树</a></li><li class="post-list-item"><a class="post-list-link" href="/learngit/2018/03/09/统计机器学习基础概念/">统计机器学习基本概念</a></li><li class="post-list-item"><a class="post-list-link" href="/learngit/2018/03/05/hello-world/">Hello World</a></li></ul></div><div class="widget"><div class="widget-title"><i class="fa fa-external-link"> 友情链接</i></div><ul></ul><a href="https://github.com/GaoJianchao" title="github" target="_blank">github</a><ul></ul><a href="http://di1shuai.com" title="朱帅的博客" target="_blank">朱帅的博客</a><ul></ul><a href="https://github.com/BestBurning/maupassant-hexo" title="Maupassant" target="_blank">Maupassant</a></div></div></div><div class="pure-u-1 pure-u-md-3-4"><div id="footer">Copyright © 2018 <a href="/learngit/." rel="nofollow">潇洒一世|</a> Powered by<a rel="nofollow" target="_blank" href="https://hexo.io"> Hexo.</a> My<a rel="nofollow" target="_blank" href="https://github.com/GaoJianchao"> Github.</a></div></div></div><a class="show" id="rocket" href="#top"></a><script type="text/javascript" src="/learngit/js/totop.js?v=0.0.0" async></script><script type="text/javascript" src="//cdn.bootcss.com/fancybox/3.2.5/jquery.fancybox.min.js" async></script><script type="text/javascript" src="/learngit/js/fancybox.js?v=0.0.0" async></script><link rel="stylesheet" type="text/css" href="//cdn.bootcss.com/fancybox/3.2.5/jquery.fancybox.min.css"><script type="text/javascript" src="//cdn.bootcss.com/mathjax/2.7.2/MathJax.js?config=TeX-MML-AM_CHTML" async></script><script type="text/javascript" src="/learngit/js/codeblock-resizer.js?v=0.0.0"></script><script type="text/javascript" src="/learngit/js/smartresize.js?v=0.0.0"></script></div></body></html>